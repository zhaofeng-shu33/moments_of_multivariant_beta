\documentclass{elsarticle}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mathtools}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}
\def\E{\mathbb{E}}
\def\Beta{\textrm{Beta}}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{cor}{Corollary}
\title{Second-order matrix extension of Beta Distribution}
\author{Feng Zhao}
\begin{document}
 \begin{abstract}
In this article, we consider a two order matrix extension of Beta distribution,
that is, a distribution on two order random definite matrix.
 \end{abstract}
\begin{keyword}
 multivariate Beta distribution \sep higher order moment
\end{keyword}
\maketitle
\section{Introduction}
\citet{olkin1964} introduce an extension of
multivariate extension for Beta distribution,
denoted as $\Beta_p(\alpha, \beta)$.
It is a random $p\times p$  symmetric matrix $W$ whose distribution
is given by
\begin{align}
p(W) &= \frac{1}{B_p(\alpha, \beta)}\abs{I-W}^{\alpha-\frac{p+1}{2}}
\abs{W}^{\beta-\frac{p+1}{2}} \textrm{ where } W, I-W \in S_{p,p}^{++}
\label{eq:distr}\\
B_p(\alpha, \beta) &= \int_{W,I-W \in S_{p,p}^{+} }\abs{I-W}^{\alpha-\frac{p+1}{2}}
\abs{X}^{\beta-\frac{p+1}{2}}dX \textrm{ where } \alpha, \beta > \frac{p-1}{2}
\end{align}
$B_p(\alpha, \beta)$ is called the multivariate Beta function (\citet{david1981}).
When $p=1$, the distribution reduces to normal Beta distribution for
$0<x<1$.

This extension has many useful applications in multivariate statistical
problems but little is known about the analytical property of such extension.
In this paper, we focus on the case $p=2$ and deduce the analytical form of 
higher order moments for $\Beta_2(\alpha, \beta)$. This formula
includes the expectation and variance, which are the first and second
order moment respectively. The higher order moment formula, as
far as we know, is novel and can be used directly in the computation
related with multivariate Beta models instead of approximate
numerical integration.

In this article, the following notation convention is adopted:
$W=\begin{pmatrix} X & Z \\ Z & Y \end{pmatrix}$ is the symmetric random
matrix to be considered. Its distribution is given by Equation \eqref{eq:distr}.
$\abs{W}=XY-Z^2$ is the determinant of matrix $W$.
Let $\E_{\alpha,\beta}[f(X,Y, Z)] = \int f(X,Y,Z)p(W)dW$ denotes the expectation
with $\Beta_2(\alpha, \beta)$ where $f(X, Y, Z)$ is a function with three
variables. We will compute $\E_{\alpha,\beta}[f(X,Y, Z)]$
when $f(X,Y,Z)$ takes the monomial form: $f(X,Y,Z)=X^m Y^r Z^{2t}$.

\section{Marginal Distribution}
In this section we will compute $\E_{\alpha,\beta}[f(X,Y, Z)]$
for $f(X,Y,Z)=X^m$. That is, we consider the marginal distribution for $X$,
which turns out to be one dimensional Beta distribution.
To accomplish this goal, we need the following lemma:
\begin{lemma}\label{lem:AB}
Let $A = XY - Z^2, B = 1 - X - Y + A$, then we have
\begin{align}
\E_{\alpha, \beta}[Af(X,Y,Z)] =&
\frac{\alpha(\alpha-1/2)}{(\alpha+\beta)(\alpha+\beta-1/2)}\E_{\alpha+1, \beta}[f(X,Y,Z)]
\label{eq:Aexp} \\
\E_{\alpha,\beta}[Bf(X,Y,Z)] =&
\frac{\beta(\beta-1/2)}{(\alpha+\beta)(\alpha+\beta-1/2)}\E_{\alpha, \beta+1}[f(X,Y,Z)]
\label{eq:Bexp}
\end{align}
\end{lemma}
\begin{proof}
For multivariant Beta function we have
$\Beta_p(a, b) = \frac{\Gamma_p(a)\Gamma_p(b)}{\Gamma_p(a+b)}$
where $\Gamma_p$ is the multivariant Gamma function.
For $p=2$ we have $\Gamma_2(a) = \sqrt{\pi}\Gamma(a)\Gamma(a-1/2)$.
\begin{align*}
\frac{\E_{\alpha, \beta}[Af(X,Y,Z)]}{\E_{\alpha+1, \beta}[Af(X,Y,Z)]} &
=\frac{B_2(\alpha+1,\beta)}{B_2(\alpha,\beta)}\\
&=\frac{\Gamma_2(\alpha+1)}{\Gamma_2(\alpha)}
\frac{\Gamma_2(\alpha+\beta)}{\Gamma_2(\alpha+\beta+1)}\\
& =\frac{\Gamma(\alpha+1)}{\Gamma(\alpha)}
\frac{\Gamma(\alpha+1/2)}{\Gamma(\alpha-1/2)}
\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha+\beta+1)}
\frac{\Gamma(\alpha+\beta-1/2)}{\Gamma(\alpha+\beta+1/2)}\\
&=\frac{\alpha(\alpha-1/2)}{(\alpha+\beta)(\alpha+\beta-1/2)}
\end{align*}
Thus Equation \eqref{eq:Aexp} is proved and Equation \eqref{eq:Bexp} follows similarly.
\end{proof}
Using the above Lemma, we give the main conclusion of this section:
\begin{theorem}\label{thm:Xm}
$\E_{\alpha, \beta}[X^m] =
\prod_{i=0}^{m-1}\frac{\alpha+i}{\alpha+\beta+i}$, thus $X$
conforms to Beta distribution $\Beta(\alpha, \beta)$
\end{theorem}
\begin{proof}
Since the position of $X$ and $Y$ is symmetric,
$\E_{\alpha, \beta}[X]=\E_{\alpha, \beta}[Y]$.
Taking the expectation about $\Beta_2(\alpha, \beta)$
on both sides of $B=1-X-Y+A$ and using the
conclusion of Lemma \ref{lem:AB} we have
\begin{equation*}
\frac{\beta(\beta-1/2)}{(\alpha+\beta)(\alpha+\beta-1/2)}
= 1 - 2\E_{\alpha, \beta}[X] +
\frac{\alpha(\alpha-1/2)}{(\alpha+\beta)(\alpha+\beta-1/2)}
\end{equation*}
Solving the about equation we get
$\E_{\alpha, \beta}[X]=\frac{\alpha}{\alpha + \beta}$.
Recursively using Equation \eqref{eq:Aexp} with $f(X,Y,Z)=X$
we have $\E_{\alpha, \beta}[X^m] =
\prod_{i=0}^{m-1}\frac{\alpha+i}{\alpha+\beta+i}$.
This expression of higher order moment
is the same with that of Beta distribution and by
the uniqueness of moment generating function, we
conclude that $X$ is actually Beta distribution $B(\alpha,
\beta)$.
\end{proof}
\section{Mixed Moment}
In this section, we further compute $\E_{\alpha,\beta}[X^mZ^{2t}]$.
By symmetric property  $\E_{\alpha,\beta}[X^mZ^{2t+1}] = 0$.
Therefore we only need to consider the case when the power of $Z$
is even.
\begin{theorem}\label{thm:mm}
\begin{equation}\label{eq:ZXtm}
\E_{\alpha, \beta}[X^mZ^{2t}] = \frac{(2t-1)!!}{2^t}
\prod_{i=0}^{t-1}
\frac{\beta+i}{(\alpha+\beta+i-1/2)}
\frac{\prod_{i=0}^{t+m-1}\alpha+i}{\prod_{i=0}^{2t+m-1}
\alpha+\beta+i}
\end{equation}
\end{theorem}
\begin{proof}
We use induction to show Equation \eqref{eq:ZXtm} is true.
Firstly, Equation \eqref{eq:ZXtm} is true for $t=0$ from 
Theorem \ref{thm:Xm}. Let $A, B$ be the same as those
in Lemma \ref{lem:AB}.
Suppose Equation \eqref{eq:ZXtm} holds for $\E[Z^{2t-2}X^m]$,
using $Z^2=XY-A=X(1-X-A+B)-A$, then
\begin{align*}
\E_{\alpha,\beta}[Z^{2t}X^m] &=
\E_{\alpha,\beta}[Z^{2t-2}X^m(X-X^2+AX-BX-A)] \\
&= \E_{\alpha,\beta}[Z^{2t-2}(X^{m+1} - X^{m+2})] +
\E_{\alpha,\beta}[A Z^{2t-2} (X^{m+1} - X^m)] -
\E_{\alpha,\beta}[BZ^{2t-2} X^{m+1}] \\
&= \left(1-\frac{\alpha+t+m}{\alpha+\beta+2t+m-1}
\right)\E_{\alpha, \beta}[Z^{2t-2}X^{m+1}] \\
&+
\frac{\alpha(\alpha-1/2)}{(\alpha+\beta)(\alpha+\beta-1/2)}
\E_{\alpha+1,\beta}[Z^{2t-2}(X^{m+1} - X^m)] \\
&-\frac{\beta(\beta-1/2)}{(\alpha+\beta)(\alpha+\beta-1/2)}
\E_{\alpha,\beta+1}[Z^{2t-2}X^{m+1}]\\
&=\frac{\beta+t-1}{\alpha+\beta + 2t+m-1}
\E_{\alpha,\beta}[Z^{2t-2}X^{m+1}] \\
&+\frac{(\alpha+t+m)(\alpha-1/2)}{(\alpha+\beta+2t-1+m)(\alpha+\beta + t - 3/2)}
\left(1-\frac{\alpha+\beta+2(t-1)+m+1}{\alpha+t+m}\right)
\E_{\alpha, \beta}[Z^{2t-2}X^{m+1}] \\
&-\frac{(\beta+t-1)(\beta-1/2)}{(\alpha+\beta+2t-1+m)(\alpha+\beta + t - 3/2)}
\E_{\alpha,\beta}[Z^{2t-2}X^{m+1}]\\
&=\frac{(t-1/2)(\beta+t-1)}{(\alpha+\beta+t-3/2)(\alpha+\beta+2t+m-1)}
\E_{\alpha, \beta}[Z^{2t-2}X^{m+1}]
\end{align*}
Using Equation \eqref{eq:ZXtm} for $t-1$
we can get the same form of expression for $t$.
\end{proof}
From Theorem \ref{thm:mm},
using $X^m Y^r Z^{2t} = X^m(A+Z^2)^r Z^{2t} $ and
binomial theorem we can get
the general formula for the mixed moment:
\begin{cor}
\begin{align}
\E_{\alpha, \beta}[X^mY^rZ^{2t}] &= \frac{(2t-1)!!}{2^t}
\frac{\prod_{j=0}^{t-1} (\beta+j)}{\prod_{j=0}^{t+r-1} (\alpha+\beta-1/2+j)}
\frac{\prod_{j=0}^{t+m-1}(\alpha+j)}{\prod_{j=0}^{2t+m-1} (\alpha+\beta+j)}\notag\\
&\cdot\sum_{i=0}^r \frac{1}{2^i}\binom{r}{i}\prod_{j=1}^i (2t-1+2j)
\frac{\displaystyle\prod_{j=0}^{r-i-1}(\alpha-1/2+j)
\prod_{j=0}^{i-1}(\beta+j+t)}{\prod_{j=0}^{i-1}(\alpha+\beta+j+2t+m)}
\end{align}
\end{cor}
\bibliographystyle{elsarticle-harv}
\bibliography{exportlist}
\end{document}