\documentclass{elsarticle}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mathtools}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}
\def\E{\mathbb{E}}
\def\Beta{\textrm{Beta}}
\newtheorem{lemma}{Lemma}
\title{Second-order matrix extension of Beta Distribution}
\author{Feng Zhao}
\begin{document}
 \begin{abstract}
In this article, we consider a two order matrix extension of Beta distribution,
that is, a distribution on two order random definite matrix.
 \end{abstract}
\begin{keyword}
 multivariate Beta distribution \sep higher order moment
\end{keyword}
\maketitle
\section{Introduction}
\citet{olkin1964} introduce an extension of
multivariate extension for Beta distribution,
denoted as $\Beta_p(\alpha, \beta)$.
It is a random $p\times p$  symmetric matrix $W$ whose distribution
is given by
\begin{align}
p(W) &= \frac{1}{B_p(\alpha, \beta)}\abs{I-W}^{\alpha-\frac{p+1}{2}}
\abs{W}^{\beta-\frac{p+1}{2}} \textrm{ where } W, I-W \in S_{p,p}^{++}
\label{eq:distr}\\
B_p(\alpha, \beta) &= \int_{W,I-W \in S_{p,p}^{+} }\abs{I-W}^{\alpha-\frac{p+1}{2}}
\abs{X}^{\beta-\frac{p+1}{2}}dX \textrm{ where } \alpha, \beta > \frac{p-1}{2}
\end{align}
$B_p(\alpha, \beta)$ is called the multivariate Beta function (\citet{david1981}).
When $p=1$, the distribution reduces to normal Beta distribution for
$0<x<1$.

This extension has many useful applications in multivariate statistical
problems but little is known about the analytical property of such extension.
In this paper, we focus on the case $p=2$ and deduce the analytical form of 
higher order moments for $\Beta_2(\alpha, \beta)$. This formula
includes the expectation and variance, which are the first and second
order moment respectively. The higher order moment formula, as
far as we know, is novel and can be used directly in the computation
related with multivariate Beta models instead of approximate
numerical integration.

In this article, the following notation convention is adopted:
$W=\begin{pmatrix} X & Z \\ Z & Y \end{pmatrix}$ is the symmetric random
matrix to be considered. Its distribution is given by Equation \eqref{eq:distr}.
$\abs{W}=XY-Z^2$ is the determinant of matrix $W$.
Let $\E_{\alpha,\beta}[f(X,Y, Z)]$ denotes the expectation
with $\Beta_2(\alpha, \beta)$ where $f(X, Y, Z)$ is a function with three
variables. We will compute $\E_{\alpha,\beta}[f(X,Y, Z)]$
when $f(X,Y,Z)$ takes the monomial form: $f(X,Y,Z)=X^m Y^r Z^{2t}$.

\section{Marginal Distribution}
In this section we will compute $\E_{\alpha,\beta}[f(X,Y, Z)]$
for $f(X,Y,Z)=X^m$. That is, we consider the marginal distribution for $X$.
To accomplish this goal, we need the following lemma:
\begin{lemma}
Let $A = XY - Z^2, B = 1 - X - Y + A$, then we have
\begin{align}
\E_{\alpha, \beta}[Af(X,Y,Z)] =&
\frac{\alpha(\alpha-1/2)}{(\alpha+\beta)(\alpha+\beta-1/2)}\E_{\alpha+1, \beta}[f(X,Y,Z)] \\
\E_{\alpha,\beta}[Bf(X,Y,Z)] =& \frac{\beta(\beta-1/2)}{(\alpha+\beta)(\alpha+\beta-1/2)}\E_{\alpha, \beta+1}[f(X,Y,Z)]
\end{align}
\end{lemma}
\bibliographystyle{elsarticle-harv}
\bibliography{exportlist}
\end{document}